# -*- coding: utf-8 -*-
"""Group_5-Shark_attack.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kEVasq25vHIioSR-LKiP03wvEWU-PT4P
"""

# TO-DO

# Check out this video: https://www.youtube.com/watch?v=bDhvCp3_lYw

# CLEANING DUTIES:
# - Column 'Date' : Check with Garima
# - Column 'Year' : Check with Garima
# - Column 'Type'
# - Column 'Country'
# - Column 'State'
# - Column 'Activity'
# - Column 'Injury' -- Injury: fatal 0, non-fatal 1, not specified -1? String would also work if uniformal (ofc) - Nicole (we can probably iterate here over the column, see minute 31:00 in YT video)
# - Column 'Time' : Check with Marco
# - Column 'Species' : Done

# A thought, can we also punt statistics that we learned during W2day3, grouping etc.? - Yey we should try to find correlation etc

#Notes - Nicole
# df.fillna('not specified) - we could fill this across the whole dataframe
# we need a no injury too

# Data import
import pandas as pd
url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'
df = pd.read_excel(url, usecols=["Date","Year","Type","Country","State","Activity","Injury","Time", "Species "]).squeeze("columns")

#We could add column_season (please make sure which season since northern / southern hemisphere)

#objective: advisory role for when not to surf in AUSTRALIA

# Remove rows that only contain NaN values
df2 = df.dropna(how='all').reset_index(drop=True)
df2

# Formatting to lowercase
df_lower = df2.applymap(lambda x: x.lower() if isinstance(x, str) else x)
df_lower

# Filtering on activity Surfing
# df_activity = df_lower[(df['Activity'] == "surfing") | (df['Activity'] == "NaN")]
df_activity = df_lower[(df_lower['Activity'] == "surfing")]
df_activity

# Removing duplicates withing column Activity
df_dup_removed = df_activity.drop_duplicates()
df_dup_removed.reset_index(drop=True)
df_dup_removed

# Rename back to df
df = df_dup_removed

# Codeblock for cleaning column 'species' - Maurits

df = df.rename(columns={'Species ': 'species'})
df['species'] = df['species'].str.strip() # remove whites
df['species'] = df['species'].str.lower() # lower case (although this was already done)
df['species'] = df['species'].str.replace(r'[^a-z\s]', '', regex=True) # replace anything but characters
# df['species'] = df['species'].apply(lambda x: 'not specified' if len(str(x)) > 40 else x) #replaces strings longer than 40 characters

#still trying to find a formula that searches for "contains" and replaces it with a value

# # Replace any occurrence containing 'bull' with 'bull shark'
df['species'] = df['species'].str.replace(r'bul.*', 'bull shark', regex=True)
df['species'] = df['species'].str.replace(r'black.*', 'blacktip shark', regex=True)
df['species'] = df['species'].str.replace(r'bronze.*', 'bronze whaler', regex=True)
df['species'] = df['species'].str.replace(r'white.*', 'white shark', regex=True)
df['species'] = df['species'].str.replace(r'wfit.*', 'white shark', regex=True)
df['species'] = df['species'].str.replace(r'spin.*', 'spinner shark', regex=True)
df['species'] = df['species'].str.replace(r'tig.*', 'tiger shark', regex=True)
df['species'] = df['species'].str.replace(r'hamm.*', 'hammer shark', regex=True)
df['species'] = df['species'].str.replace(r'wobb.*', 'wobbegong shark', regex=True)
df['species'] = df['species'].str.replace(r'lemon.*', 'lemon shark', regex=True)
df['species'] = df['species'].str.replace(r'reef.*', 'reef shark', regex=True)
df['species'] = df['species'].str.replace(r'nurse.*', 'nurse shark', regex=True)

#replaces strings longer than 15 characters with "other shark"

# df['species'] = df['species'].replace(['unknown', 'n/a', ''], 'not specified')
# df['species'] = df['species'].str.replace(r(len(str(species)) > 15), 'other shark', regex=True)
# df['species'] = str(df['species'])
# df['species'] = df['species'].apply(lambda x: 'other shark' if str(len(x)) > 15 else x)

replacement_value = 'other shark'
df['species'] = df['species'].apply(lambda x: replacement_value if isinstance(x, str) and len(x) > 15 else x)
# df['species'] = df['species'].apply(lambda x: replacement_value if len(x) > 15 else x)

value_counts = df['species'].value_counts()

# Step 2: Identify the values that have a count of less than 2
values_to_replace = value_counts[value_counts < 3].index

# Step 3: Replace these values in the DataFrame
df['species'] = df['species'].replace(values_to_replace, 'other shark')

# # Loop through the DataFrame and replace long values
# for i in range(len(df['species'])):
#     if len(df['species'].at[i, 'text_column']) > 15:
#         df['species'].at[i, 'text_column'] = replacement_value



# df['species'].apply(lambda x: 0 if x == 'C' else (1 if x == 'Q' else 2))
# # for i in ['species']:
# #   if i > str(len(15)):
# #     replace(i,'')

# species_list = ['species']
# for species in species_list:
#   if len(species)>15:
#     species_list[species_list.index(species)] = 'other shark'

# print(species_list)

# replacements = {
#     'white shark': 'great white shark',
#     'bullshark': 'bull shark',
#     'shark': 'not specified',
#     'NaN': '',
#     'blacktip': 'blacktip shark'
#     # Add other replacements as needed
# }
# df['species'] = df['species'].replace(replacements)


df['species'] = df['species'].replace(['unknown', 'n/a', ''], 'not specified')
df = df.reset_index(drop=True)
# unique_values = df['species'].unique()
# unique_sorted = set(unique_values)
# unique_sorted
set(df['species'])

# Block Nicole's Injury

#Split the columns in two - 'Primary_Injury' and 'Secondary_Detail'
df['Primary_Injury'] = df['Injury'].str.split(',',n=1, expand=True).iloc[:,0]
df['Secondary_Detail'] = df['Injury'].str.split(',',n=1, expand=True ).iloc[:,1]

#Create a condition that checks for 'no injury' and 'fatal'
condition = df['Primary_Injury'].isin(['no injury', 'fatal'])

#Apply the condition and replace other values with 'non fatal'
df['Primary_Injury'] = df['Primary_Injury'].where(condition, 'non fatal')

#We should drop the 'Injury' column
# df_without Injury = df.drop('Injury', axis=1) we will create a new dataframe
# df.drop('Injury', axis=1, inplace=True) this will retain the dataframe
df = df.drop(columns=['Injury'])

# Block Marco - Time column
df_time = df['Time'].unique()
df_time

# Cleaning the Time column
import numpy as np
df['Time']= df['Time'].replace({
    'early  morning': '07h00',
    'sunset': '19h00',
    'early afternoon' : '16h00',
    'late afternoon' : '18h00',
    'evening' : '20h00',
    'sometime between 06h00 & 08hoo' : '07h00',
    '07h00 - 08h00' : '07h30',
    '0830' : '08h30',
    'just before noon' : '11h30',
    'am' : '09h00',
    'dusk' : '21h00',
    '"just before 11h00"' : '10h30',
    'just before sundown' : '19h30',
    '17h00 or 17h40' : '17h00',
    '--' : '12h00',
    '09h00 -10h00' : '09h30',
    '20h45 (sunset)' : '20h45',
    'p.m.' : '17h00',
    '8:04 pm' : '08h04',
    'after dusk' : '21h30',
    'noon' : '12h00',
    '30 minutes after 1992.07.08.a' : '08h30',
    '17h00 sunset' : '17h00',
    'x' : '12h00',
    '18h30 (sunset)' : '18h30',
    '06j00' : '06h00',
    '16h30 or 18h00' : '17h15',
    'night' : '24h00',
    'morning' : '10h00',
    'early morning' : '09h00',
    'midday' : '12h00',
    'afternoon' : '17h00',
    '10jh45' : '10h45',
    '9h00' : '09h00',
    1300 : '13h00',
    '11h115' : '11h15',
    'after noon' : '12h30',
    '14h00-15h00' : '14h30'
})

# Function to categorized all inputs in the Time column
def categorize_time(df_time):
    if pd.isna(df_time):
        return np.nan
    hour = int(df_time.split("h")[0])

    if 6 <= hour < 12:
        return 'morning'
    elif 12 <= hour < 18:
        return 'afternoon'
    elif 18 <= hour < 24:
        return 'evening'
    else:
        return 'night'

# Apply categorization
df_timeday = df['Time'].apply(categorize_time) # Categorizing all times
#df_timeday = df["Time"].fillna('undefined') # All non values changes to "undefined"
df_timeday

df['timeday'] = df['Time'].apply(categorize_time)
df

pivot_time = pd.pivot_table(df, index='timeday', columns = 'Primary_Injury', aggfunc = 'size')
pivot_time

pivot_prov = pd.pivot_table(df, index='Type', columns = 'Primary_Injury', aggfunc = 'size')
pivot_prov

import seaborn as sns

sns.countplot(x='timeday', data=df)

sns.countplot(x='Primary_Injury', data=df)

import matplotlib.pyplot as plt
country_counts = df['Country'].value_counts()
top_10_countries = country_counts.head(10).index
df_top_10 = df[df['Country'].isin(top_10_countries)]
plt.figure(figsize=(10, 6))
sns.countplot(x='Country', data=df_top_10, order=top_10_countries)
plt.xticks(rotation=45)  # Rotate the labels if necessary
plt.title('Top 10 Countries by Count')
plt.show()

species_counts = df['species'].value_counts()
top_10_species = species_counts.head(10).index
df_top_10_species = df[df['species'].isin(top_10_species)]
plt.figure(figsize=(10, 6))
sns.countplot(x='species', data=df_top_10_species, order=top_10_species)
plt.xticks(rotation=45)  # Rotate the labels if necessary
plt.title('Top 10 Species by Count')
plt.show()



df = df.drop(columns=['Date'])

# to be used at the end (replaces all the NaN with empty spaces. Looks way cleaner)
df = df.fillna('')
df.nunique()

df['Year'] = df['Year'].astype(int)
df

# # Block for cleaning column 'Date' - Garima
# df['Date'] = pd.to_datetime(df['Date'], format='%d %b %Y', errors='coerce')

# # Format the 'Date' column to 'DD-MM-YYYY'
# df['FormattedDate'] = df['Date'].dt.strftime('%d-%m-%Y')

# # Display the 'FormattedDate' column
# # print(df['FormattedDate'].isna().sum())

# non_null_rows = df[df['FormattedDate'].notna()]

# # Display the filtered DataFrame
# # print(df_dup_removed['Year'].isna().sum())
# # print(non_null_rows)

# df['Year'] = df['Year'].astype('int')

# #df['Time'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.time

# # Step 3: Format the 'Time' column to '12-hour clock with AM/PM'
# df['FormattedTime'] = df['Time'].apply(lambda x: x.strftime('%I:%M %p') if pd.notna(x) else 'Invalid Time')

# # Display the DataFrame
# df

#df['Type'].unique()

#main_categories = ['unprovoked', 'provoked']

#df['Type'] = df['Type'].apply(lambda x: x if x in main_categories else 'other')

display (df)